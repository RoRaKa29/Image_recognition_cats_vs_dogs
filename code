import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import load_img, img_to_array
import os
img_dir =  r'C:\Users\kaczj\Downloads\cats_vs_dogs\train'
images = os.listdir(img_dir)
def show_rgb_layers(image, subplots_args=dict()):
    '''
    Show RGB layers of the image on separate axes.
    '''
    
    im_shape = image.shape

    assert image.ndim == 3

    assert im_shape[-1] == 3

    fig, ax = plt.subplots(ncols=3)
    for idx, layer in enumerate(['Reds', 'Greens', 'Blues']):
        ax[idx].imshow(image[:, :, idx], cmap=layer)
    
    return fig
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv2D, MaxPooling2D, Flatten
from keras.models import load_model
from keras.callbacks import EarlyStopping

stop_early = EarlyStopping(patience=2)
from keras.layers import Dropout, BatchNormalization


from imports_for_ML2 import load_images

X, y = load_images(img_dir, n_images=10000, resize=(60, 60))

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=23)


model = Sequential([
Conv2D(32, (3, 3), input_shape=(60, 60, 3), activation='relu'),
BatchNormalization(),
Conv2D(32, (3, 3), activation='relu'),
MaxPooling2D(pool_size=(2, 2)),
Conv2D(64, (3, 3), activation='relu'),
BatchNormalization(),
Conv2D(64, (3, 3), activation='relu'),
MaxPooling2D(pool_size=(2, 2)),
Conv2D(128, (3, 3), activation='relu'),
BatchNormalization(),
Conv2D(128, (3, 3), activation='relu'),
MaxPooling2D(pool_size=(2, 2)),
Flatten(),
Dense(64, activation='relu'),
Dropout(0.5),
Dense(1, activation='sigmoid'),

    ])
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
stop_early = EarlyStopping(patience=6)
history = model.fit(X_train, y_train, epochs=20, validation_split=0.04, callbacks=[stop_early])


plt.plot(history.history['loss'] ,'bo',label='training loss', )
plt.plot(history.history['val_loss'], label='validation loss')
plt.title('training and validation loss')
plt.legend()


train_corr = model.evaluate(X_train, y_train)[1]
print('Accuracy on the training data:')
print(train_corr)

test_corr = model.evaluate(X_test, y_test)[1]
print('\nAccuracy on the test data:')
print(test_corr)

print('Loss of the function is :',history.history['loss'][-1])
